{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb9q2_QZgdNk"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple StockÂ Trading Using Ensemble Strategy\n",
        "\n",
        "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
        "\n",
        "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
        "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a âˆˆ A includes three actions: a âˆˆ {âˆ’1, 0, 1}, where âˆ’1, 0, 1 represent\n",
        "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
        "an action space {âˆ’k, ..., âˆ’1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or âˆ’10, respectively\n",
        "\n",
        "* Reward function: r(s, a, sâ€²) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, sâ€²) = vâ€² âˆ’ v, where vâ€² and v represent the portfolio\n",
        "values at state sâ€² and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPT0ipYE28wL",
        "outputId": "01f1fc62-0fba-4f38-eb2e-329910985659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wrds in /usr/local/lib/python3.9/site-packages (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from wrds) (1.24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from wrds) (2.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (from wrds) (1.10.1)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.9/site-packages (from wrds) (1.4.47)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.9/site-packages (from wrds) (2.9.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/site-packages (from sqlalchemy<2->wrds) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->wrds) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/site-packages (from pandas->wrds) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->wrds) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting swig\n",
            "  Using cached swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "Installing collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mâœ¨ðŸ°âœ¨ Everything looks OK!\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-s9w6j1g7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-s9w6j1g7\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 8a75a4bbb28f86f88ee2d4bd9a8c19cce444badb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-zhb_60b_/pyfolio_1d70d0d240b14e3bbd440ae63106a59f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/quantopian/pyfolio.git /tmp/pip-install-zhb_60b_/pyfolio_1d70d0d240b14e3bbd440ae63106a59f\n",
            "  Resolved https://github.com/quantopian/pyfolio.git to commit 4b901f6d73aa02ceb6d04b7d83502e5c6f2e81aa\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-zhb_60b_/elegantrl_51bf694cfd124f9aac4ee8bcddef46f2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-zhb_60b_/elegantrl_51bf694cfd124f9aac4ee8bcddef46f2\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit bf5ecff658f46c9c8c3e09a02e72be7383bd201a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata==4.13.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (4.13.0)\n",
            "Requirement already satisfied: stockstats>=0.4.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.24.2)\n",
            "Requirement already satisfied: stable-baselines3<2.0.0,>=1.6.2 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.8.0)\n",
            "Requirement already satisfied: ccxt>=1.66.32 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.0.72)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.2.18)\n",
            "Requirement already satisfied: exchange_calendars==3.6.3 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.6.3)\n",
            "Requirement already satisfied: ray[default,tune]>=2.0.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.3.1)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.6)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.0.0)\n",
            "Requirement already satisfied: jqdatasdk in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.8.11)\n",
            "Requirement already satisfied: wrds>=3.1.6 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.1.6)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.21.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (4.3.2)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.7.1)\n",
            "Requirement already satisfied: alpaca_trade_api>=2.1.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.2.2)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.3.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2023.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2.8.2)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata==4.13.0->finrl==0.3.5) (3.15.0)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.5.1)\n",
            "Requirement already satisfied: msgpack==1.0.3 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.0.3)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.26.15)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.28.2)\n",
            "Requirement already satisfied: websockets<11,>=9.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (10.4)\n",
            "Requirement already satisfied: aiohttp==3.8.1 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (3.8.1)\n",
            "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (6.0)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (23.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (4.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from deprecation==2.1.0->alpaca_trade_api>=2.1.0->finrl==0.3.5) (23.1)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (65.6.3)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (39.0.2)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (2022.12.7)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (3.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.2.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/site-packages (from pandas>=1.1.5->finrl==0.3.5) (2023.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (8.1.3)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (3.20.3)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.54.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (3.12.0)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (20.21.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (4.17.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.10.7)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.16.0)\n",
            "Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.1)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.7.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.11.2)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.3.14)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (6.3.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.5.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.9.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (3.1.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/site-packages (from stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.0.0)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.9/site-packages (from wrds>=3.1.6->finrl==0.3.5) (1.4.47)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.9/site-packages (from wrds>=3.1.6->finrl==0.3.5) (2.9.6)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (1.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (1.16.0)\n",
            "Requirement already satisfied: thriftpy2>=0.3.9 in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (0.4.16)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (5.12.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (9.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (4.39.3)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (8.12.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.12.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.5.5)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (4.12.2)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (4.9.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (2.3.7)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (1.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (0.0.11)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.9/site-packages (from aiodns>=1.1.1->ccxt>=1.66.32->finrl==0.3.5) (4.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance->finrl==0.3.5) (2.4.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/site-packages (from cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (1.15.1)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.9/site-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.10.0)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (5.9.5)\n",
            "Requirement already satisfied: nvidia-ml-py>=11.450.129 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (11.525.112)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (1.20.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance->finrl==0.3.5) (0.5.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.5.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (3.0.38)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.9.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.5)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.15.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api>=2.1.0->finrl==0.3.5) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/site-packages (from sqlalchemy<2->wrds>=3.1.6->finrl==0.3.5) (2.0.2)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.9/site-packages (from thriftpy2>=0.3.9->jqdatasdk->finrl==0.3.5) (3.11)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.101)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.0.0)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.91)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.99)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.14.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.1)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (0.38.4)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.26.3)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (16.0.1)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[default,tune]>=2.0.0->finrl==0.3.5) (3.2.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.3.6)\n",
            "Requirement already satisfied: pyglet>=1.4.0 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.0.5)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.3.5)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/site-packages (from jsonschema->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.19.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (2.11.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.9/site-packages (from opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.1.3)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.9/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (2.21)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (2.17.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.1.2)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.2.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/site-packages (from sympy->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.2.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.4.8)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them. \n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EeMK7Uentj1V"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lPqeTTwoh1hn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w9A8CN5R5PuZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzqRRTOX6aFu",
        "outputId": "c56d5291-bd55-44b7-a196-90d4980f1c61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
          ]
        }
      ],
      "source": [
        "print(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "e2928220-fb24-4a58-de49-8afbb18d375a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (97013, 8)\n"
          ]
        }
      ],
      "source": [
        "# TRAIN_START_DATE = '2009-04-01'\n",
        "# TRAIN_END_DATE = '2021-01-01'\n",
        "# TEST_START_DATE = '2021-01-01'\n",
        "# TEST_END_DATE = '2022-06-01'\n",
        "\n",
        "TRAIN_START_DATE = '2010-01-01'\n",
        "TRAIN_END_DATE = '2021-10-01'\n",
        "TEST_START_DATE = '2021-10-01'\n",
        "TEST_END_DATE = '2023-03-01'\n",
        "\n",
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TEST_END_DATE,\n",
        "                     ticker_list = DOW_30_TICKER).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GiRuFOTOtj1Y",
        "outputId": "0d951410-d011-4e7e-c7f3-102ee9299728"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       open       high        low      close     volume   tic   \n",
              "0  2010-01-04   7.622500   7.660714   7.585000   6.505280  493729600  AAPL  \\\n",
              "1  2010-01-04  56.630001  57.869999  56.560001  42.888947    5277400  AMGN   \n",
              "2  2010-01-04  40.810001  41.099998  40.389999  33.551678    6894300   AXP   \n",
              "3  2010-01-04  55.720001  56.389999  54.799999  43.777546    6186700    BA   \n",
              "4  2010-01-04  57.650002  59.189999  57.509998  41.156898    7325600   CAT   \n",
              "\n",
              "   day  \n",
              "0    0  \n",
              "1    0  \n",
              "2    0  \n",
              "3    0  \n",
              "4    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6b8f8fb-1287-4f3f-b474-a4933dd61249\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>7.622500</td>\n",
              "      <td>7.660714</td>\n",
              "      <td>7.585000</td>\n",
              "      <td>6.505280</td>\n",
              "      <td>493729600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>56.630001</td>\n",
              "      <td>57.869999</td>\n",
              "      <td>56.560001</td>\n",
              "      <td>42.888947</td>\n",
              "      <td>5277400</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>40.810001</td>\n",
              "      <td>41.099998</td>\n",
              "      <td>40.389999</td>\n",
              "      <td>33.551678</td>\n",
              "      <td>6894300</td>\n",
              "      <td>AXP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>55.720001</td>\n",
              "      <td>56.389999</td>\n",
              "      <td>54.799999</td>\n",
              "      <td>43.777546</td>\n",
              "      <td>6186700</td>\n",
              "      <td>BA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>57.650002</td>\n",
              "      <td>59.189999</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>41.156898</td>\n",
              "      <td>7325600</td>\n",
              "      <td>CAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6b8f8fb-1287-4f3f-b474-a4933dd61249')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6b8f8fb-1287-4f3f-b474-a4933dd61249 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6b8f8fb-1287-4f3f-b474-a4933dd61249');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DSw4ZEzVtj1Z",
        "outputId": "714508b2-c639-4d3b-c359-ad182a0edfef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             date        open        high         low       close    volume   \n",
              "97008  2023-02-28  482.670013  483.359985  473.920013  474.250854   3902100  \\\n",
              "97009  2023-02-28  220.000000  221.770004  219.500000  219.940002   5385400   \n",
              "97010  2023-02-28   38.700001   38.970001   38.549999   38.178165  16685300   \n",
              "97011  2023-02-28   35.480000   35.779999   35.320000   35.529999   8847000   \n",
              "97012  2023-02-28  141.000000  142.649994  140.949997  141.549850   6018000   \n",
              "\n",
              "       tic  day  \n",
              "97008  UNH    1  \n",
              "97009    V    1  \n",
              "97010   VZ    1  \n",
              "97011  WBA    1  \n",
              "97012  WMT    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-747210eb-4cc6-4791-9ac1-f5f3896f1c6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97008</th>\n",
              "      <td>2023-02-28</td>\n",
              "      <td>482.670013</td>\n",
              "      <td>483.359985</td>\n",
              "      <td>473.920013</td>\n",
              "      <td>474.250854</td>\n",
              "      <td>3902100</td>\n",
              "      <td>UNH</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97009</th>\n",
              "      <td>2023-02-28</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>221.770004</td>\n",
              "      <td>219.500000</td>\n",
              "      <td>219.940002</td>\n",
              "      <td>5385400</td>\n",
              "      <td>V</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97010</th>\n",
              "      <td>2023-02-28</td>\n",
              "      <td>38.700001</td>\n",
              "      <td>38.970001</td>\n",
              "      <td>38.549999</td>\n",
              "      <td>38.178165</td>\n",
              "      <td>16685300</td>\n",
              "      <td>VZ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97011</th>\n",
              "      <td>2023-02-28</td>\n",
              "      <td>35.480000</td>\n",
              "      <td>35.779999</td>\n",
              "      <td>35.320000</td>\n",
              "      <td>35.529999</td>\n",
              "      <td>8847000</td>\n",
              "      <td>WBA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97012</th>\n",
              "      <td>2023-02-28</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>142.649994</td>\n",
              "      <td>140.949997</td>\n",
              "      <td>141.549850</td>\n",
              "      <td>6018000</td>\n",
              "      <td>WMT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-747210eb-4cc6-4791-9ac1-f5f3896f1c6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-747210eb-4cc6-4791-9ac1-f5f3896f1c6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-747210eb-4cc6-4791-9ac1-f5f3896f1c6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3HrZHLh1hy",
        "outputId": "942f350b-3a42-4d7c-882d-047727ad7a1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97013, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hYkeaPiICHS",
        "outputId": "cc54e3d4-1cd2-42d5-9d28-c9eb56b3c0e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       open       high        low      close     volume   tic   \n",
              "0  2010-01-04   7.622500   7.660714   7.585000   6.505280  493729600  AAPL  \\\n",
              "1  2010-01-04  56.630001  57.869999  56.560001  42.888947    5277400  AMGN   \n",
              "2  2010-01-04  40.810001  41.099998  40.389999  33.551678    6894300   AXP   \n",
              "3  2010-01-04  55.720001  56.389999  54.799999  43.777546    6186700    BA   \n",
              "4  2010-01-04  57.650002  59.189999  57.509998  41.156898    7325600   CAT   \n",
              "\n",
              "   day  \n",
              "0    0  \n",
              "1    0  \n",
              "2    0  \n",
              "3    0  \n",
              "4    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12cfebbc-9519-4116-a0e3-398de659628a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>7.622500</td>\n",
              "      <td>7.660714</td>\n",
              "      <td>7.585000</td>\n",
              "      <td>6.505280</td>\n",
              "      <td>493729600</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>56.630001</td>\n",
              "      <td>57.869999</td>\n",
              "      <td>56.560001</td>\n",
              "      <td>42.888947</td>\n",
              "      <td>5277400</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>40.810001</td>\n",
              "      <td>41.099998</td>\n",
              "      <td>40.389999</td>\n",
              "      <td>33.551678</td>\n",
              "      <td>6894300</td>\n",
              "      <td>AXP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>55.720001</td>\n",
              "      <td>56.389999</td>\n",
              "      <td>54.799999</td>\n",
              "      <td>43.777546</td>\n",
              "      <td>6186700</td>\n",
              "      <td>BA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>57.650002</td>\n",
              "      <td>59.189999</td>\n",
              "      <td>57.509998</td>\n",
              "      <td>41.156898</td>\n",
              "      <td>7325600</td>\n",
              "      <td>CAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12cfebbc-9519-4116-a0e3-398de659628a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12cfebbc-9519-4116-a0e3-398de659628a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12cfebbc-9519-4116-a0e3-398de659628a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.sort_values(['date','tic']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2vryMsdNL9H",
        "outputId": "fc5aa687-2ba2-4665-f969-8c6f51eb6769"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(df.tic.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcNyXa7RNPrF",
        "outputId": "33528401-bed4-441f-ccb4-488b59a5e7f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tic\n",
              "AAPL    3311\n",
              "AMGN    3311\n",
              "WMT     3311\n",
              "WBA     3311\n",
              "VZ      3311\n",
              "V       3311\n",
              "UNH     3311\n",
              "TRV     3311\n",
              "PG      3311\n",
              "NKE     3311\n",
              "MSFT    3311\n",
              "MRK     3311\n",
              "MMM     3311\n",
              "MCD     3311\n",
              "KO      3311\n",
              "JPM     3311\n",
              "JNJ     3311\n",
              "INTC    3311\n",
              "IBM     3311\n",
              "HON     3311\n",
              "HD      3311\n",
              "GS      3311\n",
              "DIS     3311\n",
              "CVX     3311\n",
              "CSCO    3311\n",
              "CRM     3311\n",
              "CAT     3311\n",
              "BA      3311\n",
              "AXP     3311\n",
              "DOW      994\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df.tic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007â€“2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kM5bH9uroCeg"
      },
      "outputs": [],
      "source": [
        "#  INDICATORS = ['macd',\n",
        "#                'rsi_30',\n",
        "#                'cci_30',\n",
        "#                'dx_30']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgXfBcjxtj1a",
        "outputId": "2e8d787f-51d1-4ccf-f45b-68eff0f8b616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)\n",
        "processed = processed.copy()\n",
        "processed = processed.fillna(0)\n",
        "processed = processed.replace(np.inf,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "grvhGJJII3Xn",
        "outputId": "5a2bec03-ad02-417f-f7ab-e5337b1e2c8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             date        open        high         low       close   volume   \n",
              "62206  2018-07-12  194.190002  194.259995  192.559998  168.504303  2251900  \\\n",
              "50578  2016-12-06   72.470001   72.739998   72.080002   65.801697  3843900   \n",
              "51167  2017-01-05  111.688095  112.579453  111.390976   98.599724  2766030   \n",
              "93891  2022-11-10  127.660004  129.259995  126.870003  125.987129  3159700   \n",
              "64752  2018-11-13  272.579987  273.600006  268.140015  251.892334  2516900   \n",
              "\n",
              "        tic  day      macd     boll_ub     boll_lb     rsi_30      cci_30   \n",
              "62206  AMGN    3  2.867171  169.461247  155.814223  62.633737  203.126725  \\\n",
              "50578   AXP    1  1.344500   67.630802   62.421984  62.794975   71.851005   \n",
              "51167   HON    3  0.622243   99.637668   97.401365  56.851856   57.255895   \n",
              "93891   MMM    3  2.514256  127.873858  108.315679  56.398785  128.163710   \n",
              "64752   UNH    1  1.957376  259.602054  236.030454  53.474718   68.528495   \n",
              "\n",
              "           dx_30  close_30_sma  close_60_sma  turbulence  \n",
              "62206  53.227539    161.527574    155.830422   18.437622  \n",
              "50578  33.687591     63.458170     60.429226   15.824745  \n",
              "51167   5.529101     97.592574     94.985882   13.861726  \n",
              "93891  20.706738    114.942732    117.814635   74.541524  \n",
              "64752   9.295111    248.176015    248.181654   24.163714  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bde2ce4-6ab3-4eec-b793-35f739211efb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62206</th>\n",
              "      <td>2018-07-12</td>\n",
              "      <td>194.190002</td>\n",
              "      <td>194.259995</td>\n",
              "      <td>192.559998</td>\n",
              "      <td>168.504303</td>\n",
              "      <td>2251900</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>3</td>\n",
              "      <td>2.867171</td>\n",
              "      <td>169.461247</td>\n",
              "      <td>155.814223</td>\n",
              "      <td>62.633737</td>\n",
              "      <td>203.126725</td>\n",
              "      <td>53.227539</td>\n",
              "      <td>161.527574</td>\n",
              "      <td>155.830422</td>\n",
              "      <td>18.437622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50578</th>\n",
              "      <td>2016-12-06</td>\n",
              "      <td>72.470001</td>\n",
              "      <td>72.739998</td>\n",
              "      <td>72.080002</td>\n",
              "      <td>65.801697</td>\n",
              "      <td>3843900</td>\n",
              "      <td>AXP</td>\n",
              "      <td>1</td>\n",
              "      <td>1.344500</td>\n",
              "      <td>67.630802</td>\n",
              "      <td>62.421984</td>\n",
              "      <td>62.794975</td>\n",
              "      <td>71.851005</td>\n",
              "      <td>33.687591</td>\n",
              "      <td>63.458170</td>\n",
              "      <td>60.429226</td>\n",
              "      <td>15.824745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51167</th>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>111.688095</td>\n",
              "      <td>112.579453</td>\n",
              "      <td>111.390976</td>\n",
              "      <td>98.599724</td>\n",
              "      <td>2766030</td>\n",
              "      <td>HON</td>\n",
              "      <td>3</td>\n",
              "      <td>0.622243</td>\n",
              "      <td>99.637668</td>\n",
              "      <td>97.401365</td>\n",
              "      <td>56.851856</td>\n",
              "      <td>57.255895</td>\n",
              "      <td>5.529101</td>\n",
              "      <td>97.592574</td>\n",
              "      <td>94.985882</td>\n",
              "      <td>13.861726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93891</th>\n",
              "      <td>2022-11-10</td>\n",
              "      <td>127.660004</td>\n",
              "      <td>129.259995</td>\n",
              "      <td>126.870003</td>\n",
              "      <td>125.987129</td>\n",
              "      <td>3159700</td>\n",
              "      <td>MMM</td>\n",
              "      <td>3</td>\n",
              "      <td>2.514256</td>\n",
              "      <td>127.873858</td>\n",
              "      <td>108.315679</td>\n",
              "      <td>56.398785</td>\n",
              "      <td>128.163710</td>\n",
              "      <td>20.706738</td>\n",
              "      <td>114.942732</td>\n",
              "      <td>117.814635</td>\n",
              "      <td>74.541524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64752</th>\n",
              "      <td>2018-11-13</td>\n",
              "      <td>272.579987</td>\n",
              "      <td>273.600006</td>\n",
              "      <td>268.140015</td>\n",
              "      <td>251.892334</td>\n",
              "      <td>2516900</td>\n",
              "      <td>UNH</td>\n",
              "      <td>1</td>\n",
              "      <td>1.957376</td>\n",
              "      <td>259.602054</td>\n",
              "      <td>236.030454</td>\n",
              "      <td>53.474718</td>\n",
              "      <td>68.528495</td>\n",
              "      <td>9.295111</td>\n",
              "      <td>248.176015</td>\n",
              "      <td>248.181654</td>\n",
              "      <td>24.163714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bde2ce4-6ab3-4eec-b793-35f739211efb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7bde2ce4-6ab3-4eec-b793-35f739211efb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7bde2ce4-6ab3-4eec-b793-35f739211efb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "processed.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,â€¦,-1, 0, 1,Â â€¦, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "2325d8d2-ce25-4e32-ace1-0173f1136d02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 29, State Space: 291\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 1000000, \n",
        "    \"buy_cost_pct\": 0.001, \n",
        "    \"sell_cost_pct\": 0.001, \n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "    \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms.\n",
        "\n",
        "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "v-gthCxMtj1d"
      },
      "outputs": [],
      "source": [
        "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
        "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
        "                 rebalance_window=rebalance_window, \n",
        "                 validation_window=validation_window, \n",
        "                 **env_kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KsfEHa_Etj1d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007\n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128\n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 10_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64\n",
        "                    }\n",
        "\n",
        "timesteps_dict = {'a2c' : 10_000, \n",
        "                 'ppo' : 10_000, \n",
        "                 'ddpg' : 10_000\n",
        "                 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1lyCECstj1e",
        "outputId": "fe43dd99-f73b-44c4-8e07-6c574f38874a",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  201.71708401167714\n",
            "======Model training from:  2010-01-01 to  2021-10-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_126_1\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 49        |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.0589   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -31.1     |\n",
            "|    reward             | 0.5267611 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.2       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 61        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -0.0305   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -98.9     |\n",
            "|    reward             | 0.5092787 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 9.39      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0.0495     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -34.4      |\n",
            "|    reward             | -3.2640162 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 4.39       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | 0.0202   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -20.8    |\n",
            "|    reward             | 4.051473 |\n",
            "|    std                | 0.999    |\n",
            "|    value_loss         | 4.93     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 33         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0.0267     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -305       |\n",
            "|    reward             | -2.8751447 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 66.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 4.23      |\n",
            "|    reward             | 0.6495424 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 0.0453    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.97     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 96.2      |\n",
            "|    reward             | 0.4804536 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 5.55      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 78         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 51         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 93.5       |\n",
            "|    reward             | -3.1410549 |\n",
            "|    std                | 0.997      |\n",
            "|    value_loss         | 7.37       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 58         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -552       |\n",
            "|    reward             | -2.8474367 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 196        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 63          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | -0.00321    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -375        |\n",
            "|    reward             | -0.38893893 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 228         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 67        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -134      |\n",
            "|    reward             | 7.9336367 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 20.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 74         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.455      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -90.4      |\n",
            "|    reward             | -0.5929173 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 4.22       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 81         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0136    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 3.14       |\n",
            "|    reward             | 0.26180494 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.362      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 86         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.168     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 165        |\n",
            "|    reward             | -1.3837932 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 18.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 90         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 116        |\n",
            "|    reward             | -0.7219914 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 7.91       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 97       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -78.5    |\n",
            "|    reward             | 3.03419  |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 34.8     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 104        |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | -388       |\n",
            "|    reward             | -0.7704395 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 154        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 108        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -47.2      |\n",
            "|    reward             | -0.0319608 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.7        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 83        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 66.1      |\n",
            "|    reward             | 1.329712  |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.35      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 83         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 120        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 22.5       |\n",
            "|    reward             | 0.74271923 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.76       |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2021-10-04 to  2022-01-03\n",
            "A2C Sharpe Ratio:  0.309893280201812\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_126_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 93         |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 21         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.38122717 |\n",
            "-----------------------------------\n",
            "day: 2957, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3856289.50\n",
            "total_reward: 2856289.50\n",
            "total_cost: 407124.94\n",
            "total_trades: 82359\n",
            "Sharpe: 0.768\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 92          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 44          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018455502 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.000644   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.2         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0292     |\n",
            "|    reward               | 0.7894353   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 11.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 92           |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 66           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.013540097  |\n",
            "|    clip_fraction        | 0.16         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -41.2        |\n",
            "|    explained_variance   | 0.00905      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 25.9         |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.0223      |\n",
            "|    reward               | -0.115760334 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 51.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 91          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 89          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012817072 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00182    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 13.8        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0164     |\n",
            "|    reward               | 3.018104    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 34          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 91          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 112         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019008357 |\n",
            "|    clip_fraction        | 0.219       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.0242      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.69        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0318     |\n",
            "|    reward               | -0.10554362 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 10.7        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2021-10-04 to  2022-01-03\n",
            "PPO Sharpe Ratio:  0.21116587293958214\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_126_1\n",
            "day: 2957, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3906421.00\n",
            "total_reward: 2906421.00\n",
            "total_cost: 1118.80\n",
            "total_trades: 47341\n",
            "Sharpe: 0.697\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 67        |\n",
            "|    time_elapsed    | 176       |\n",
            "|    total_timesteps | 11832     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -3.85     |\n",
            "|    critic_loss     | 398       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 8874      |\n",
            "|    reward          | 5.8852015 |\n",
            "----------------------------------\n",
            "======DDPG Validation from:  2021-10-04 to  2022-01-03\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-01-03\n",
            "======Trading from:  2022-01-03 to  2022-04-04\n",
            "============================================\n",
            "turbulence_threshold:  201.71708401167714\n",
            "======Model training from:  2010-01-01 to  2022-01-03\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_189_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -11.9      |\n",
            "|    reward             | 0.09071977 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.503      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 86          |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -115        |\n",
            "|    reward             | 0.046939574 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 15.6        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | 19.2       |\n",
            "|    reward             | -3.5236042 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 3.66       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -3.2     |\n",
            "|    reward             | 3.327144 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.835    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 84         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -5.62      |\n",
            "|    reward             | 0.25499776 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.306      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 34         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -0.0171    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -110       |\n",
            "|    reward             | -2.2478745 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 11.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -0.0294   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -74.7     |\n",
            "|    reward             | 0.3026486 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 3.93      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0.292     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 93.9      |\n",
            "|    reward             | 1.7782378 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 5.73      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 85          |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 52          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 4.34        |\n",
            "|    reward             | -0.75032014 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.712       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 57         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 101        |\n",
            "|    reward             | -0.8085534 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.56       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -51.3     |\n",
            "|    reward             | 2.3561244 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 10.7      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 85          |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 69          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0.198       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | 65.7        |\n",
            "|    reward             | -0.17207646 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 3.35        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 75       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0.27     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -2.27    |\n",
            "|    reward             | 0.408382 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.493    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -0.295     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 56.3       |\n",
            "|    reward             | -1.6909568 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 6.66       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 86        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 126       |\n",
            "|    reward             | 1.5638245 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 10.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -0.928    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 177       |\n",
            "|    reward             | 0.4588874 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 20.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | -265       |\n",
            "|    reward             | -0.2608657 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 44.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 103        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.00584    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 269        |\n",
            "|    reward             | -4.8855476 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 95.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 109       |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -11.7     |\n",
            "|    reward             | 1.3402566 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.03      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 116        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 27         |\n",
            "|    reward             | -1.1417059 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.533      |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2022-01-03 to  2022-04-04\n",
            "A2C Sharpe Ratio:  -0.21464207743719613\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_189_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 93        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 21        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 0.8477965 |\n",
            "----------------------------------\n",
            "day: 3020, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4052501.47\n",
            "total_reward: 3052501.47\n",
            "total_cost: 435181.54\n",
            "total_trades: 84506\n",
            "Sharpe: 0.850\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 90          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 45          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012901763 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00534    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.52        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0184     |\n",
            "|    reward               | -1.0799757  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 9.64        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 89          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 68          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013027647 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0148     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 15.8        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.013      |\n",
            "|    reward               | -0.51234424 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 37          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 89           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 91           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.02011177   |\n",
            "|    clip_fraction        | 0.201        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -41.2        |\n",
            "|    explained_variance   | 0.00795      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 29.7         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0224      |\n",
            "|    reward               | -0.044061303 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 49.7         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 89          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 114         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018746197 |\n",
            "|    clip_fraction        | 0.203       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.109      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.92        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0246     |\n",
            "|    reward               | -0.35882676 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 9.62        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2022-01-03 to  2022-04-04\n",
            "PPO Sharpe Ratio:  -0.11372225527122537\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_189_1\n",
            "day: 3020, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3747813.48\n",
            "total_reward: 2747813.48\n",
            "total_cost: 1028.83\n",
            "total_trades: 54376\n",
            "Sharpe: 0.676\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 66         |\n",
            "|    time_elapsed    | 182        |\n",
            "|    total_timesteps | 12084      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 6.73       |\n",
            "|    critic_loss     | 196        |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 9063       |\n",
            "|    reward          | -1.0404274 |\n",
            "-----------------------------------\n",
            "======DDPG Validation from:  2022-01-03 to  2022-04-04\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-04-04\n",
            "======Trading from:  2022-04-04 to  2022-07-06\n",
            "============================================\n",
            "turbulence_threshold:  201.71708401167714\n",
            "======Model training from:  2010-01-01 to  2022-04-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_252_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 7          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -58.3      |\n",
            "|    reward             | 0.16790466 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.34       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 68          |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 14          |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0.125       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -21.2       |\n",
            "|    reward             | -0.18084088 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.03        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.031      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -91.5      |\n",
            "|    reward             | -1.7856854 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 7.83       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 50.7      |\n",
            "|    reward             | 0.9996561 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.59      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.0374     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -21.6      |\n",
            "|    reward             | -0.9735955 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.61       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 38       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.4    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -150     |\n",
            "|    reward             | 8.113725 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 19       |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 42         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -86.1      |\n",
            "|    reward             | 0.94471526 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.73       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 83         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 48         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -61.9      |\n",
            "|    reward             | 0.80961806 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.93       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 55         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -46.6      |\n",
            "|    reward             | -0.8932571 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.85       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 61        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 113       |\n",
            "|    reward             | 1.8514563 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 11.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 66         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -139       |\n",
            "|    reward             | -0.5014913 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 17.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 83         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 72         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -183       |\n",
            "|    reward             | -2.5354702 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 40.5       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 79          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 133         |\n",
            "|    reward             | -0.05319714 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 11          |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 84        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -19.3     |\n",
            "|    reward             | 1.2642056 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.941     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 83          |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 89          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.5       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | -25.8       |\n",
            "|    reward             | 0.077466026 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 1.41        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 83        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 5.44      |\n",
            "|    reward             | -0.990725 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.0528    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 82         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 103        |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | -69.8      |\n",
            "|    reward             | 0.44744906 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.64       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 83        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 108       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 281       |\n",
            "|    reward             | 0.1552914 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 52.3      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 84           |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 113          |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.5        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -22.7        |\n",
            "|    reward             | 0.0112757115 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.457        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 83          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 119         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -6.45       |\n",
            "|    reward             | -0.89432824 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.258       |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2022-04-04 to  2022-07-06\n",
            "A2C Sharpe Ratio:  -0.19816841102518146\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_252_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 91         |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 22         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.28835934 |\n",
            "-----------------------------------\n",
            "day: 3083, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4307030.61\n",
            "total_reward: 3307030.61\n",
            "total_cost: 446645.16\n",
            "total_trades: 86029\n",
            "Sharpe: 0.770\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 89          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 45          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014908724 |\n",
            "|    clip_fraction        | 0.219       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.1       |\n",
            "|    explained_variance   | -0.0151     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.17        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0256     |\n",
            "|    reward               | 0.2774989   |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 11.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 87          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 70          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013001433 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.1       |\n",
            "|    explained_variance   | 0.00174     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 25          |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    reward               | -5.421628   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 64.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 87          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 93          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010766955 |\n",
            "|    clip_fraction        | 0.119       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.00317     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 14.3        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0156     |\n",
            "|    reward               | -1.5618522  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 47.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 87          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 117         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018587431 |\n",
            "|    clip_fraction        | 0.21        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.11       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.23        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0242     |\n",
            "|    reward               | -0.36106122 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 13.3        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2022-04-04 to  2022-07-06\n",
            "PPO Sharpe Ratio:  -0.3359738809688555\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_252_1\n",
            "day: 3083, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4780597.69\n",
            "total_reward: 3780597.69\n",
            "total_cost: 1166.44\n",
            "total_trades: 37067\n",
            "Sharpe: 0.780\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 66        |\n",
            "|    time_elapsed    | 186       |\n",
            "|    total_timesteps | 12336     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 9.73      |\n",
            "|    critic_loss     | 41.7      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 9252      |\n",
            "|    reward          | 1.7702416 |\n",
            "----------------------------------\n",
            "======DDPG Validation from:  2022-04-04 to  2022-07-06\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-07-06\n",
            "======Trading from:  2022-07-06 to  2022-10-04\n",
            "============================================\n",
            "turbulence_threshold:  201.71708401167714\n",
            "======Model training from:  2010-01-01 to  2022-07-06\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_315_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 7          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.331      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -27.3      |\n",
            "|    reward             | 0.40662116 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.941      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 67       |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | -0.0677  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -31.6    |\n",
            "|    reward             | 2.177538 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 4.13     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0.0359    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -100      |\n",
            "|    reward             | -4.789476 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 11.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 79         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -38.4      |\n",
            "|    reward             | -0.2852726 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.4        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0339    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -153       |\n",
            "|    reward             | -2.0169303 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 15         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 131       |\n",
            "|    reward             | 1.9756281 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 15.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 43        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -1.88     |\n",
            "|    reward             | 0.7303597 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.22      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 80        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 49        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 59.4      |\n",
            "|    reward             | 0.3365936 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.39      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 56        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -0.0176   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 8.19      |\n",
            "|    reward             | -0.538894 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.18      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 62         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 70.3       |\n",
            "|    reward             | 0.90524167 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.46       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 82        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 66        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -0.0193   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -7.98     |\n",
            "|    reward             | 2.2568326 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 4.32      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 74       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.4    |\n",
            "|    explained_variance | -0.102   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 9.94     |\n",
            "|    reward             | 5.30488  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 9.88     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 80          |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 81          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0.298       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 13.6        |\n",
            "|    reward             | -0.02049675 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.26        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 85         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -0.372     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -63.5      |\n",
            "|    reward             | -0.2130414 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.18       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 91       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0.179    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -224     |\n",
            "|    reward             | 4.766561 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 29.1     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 98        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -0.1      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -152      |\n",
            "|    reward             | 1.3889683 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 14.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 104        |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 83.2       |\n",
            "|    reward             | -1.7879765 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 4.53       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 81        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 109       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -6.07e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -19.5     |\n",
            "|    reward             | -9.176153 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 23.6      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 115         |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 21.4        |\n",
            "|    reward             | -0.14676909 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.47        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 81          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 123         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 89.6        |\n",
            "|    reward             | -0.22966366 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 6.01        |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2022-07-06 to  2022-10-04\n",
            "A2C Sharpe Ratio:  -0.27470979811407414\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_315_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 89        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 22        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 0.7847891 |\n",
            "----------------------------------\n",
            "day: 3146, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3897023.08\n",
            "total_reward: 2897023.08\n",
            "total_cost: 467510.86\n",
            "total_trades: 87737\n",
            "Sharpe: 0.722\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 88          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 46          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014982534 |\n",
            "|    clip_fraction        | 0.206       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.011       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 7.37        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0252     |\n",
            "|    reward               | 3.1253424   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 14.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 87          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 69          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018198758 |\n",
            "|    clip_fraction        | 0.194       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.00164     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 18.3        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0153     |\n",
            "|    reward               | 2.8794682   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 79.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 87          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 94          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019189056 |\n",
            "|    clip_fraction        | 0.192       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.016       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 34          |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0201     |\n",
            "|    reward               | 0.8512624   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 49.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 87          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 117         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025167529 |\n",
            "|    clip_fraction        | 0.209       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | -0.0244     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.86        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0211     |\n",
            "|    reward               | 0.33155695  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 19.9        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2022-07-06 to  2022-10-04\n",
            "PPO Sharpe Ratio:  -0.26667773584243265\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_315_1\n",
            "day: 3146, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3401695.54\n",
            "total_reward: 2401695.54\n",
            "total_cost: 1036.89\n",
            "total_trades: 43548\n",
            "Sharpe: 0.653\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 64         |\n",
            "|    time_elapsed    | 195        |\n",
            "|    total_timesteps | 12588      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -19.5      |\n",
            "|    critic_loss     | 882        |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 9441       |\n",
            "|    reward          | -0.2979001 |\n",
            "-----------------------------------\n",
            "======DDPG Validation from:  2022-07-06 to  2022-10-04\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-10-04\n",
            "======Trading from:  2022-10-04 to  2023-01-04\n",
            "Ensemble Strategy took:  29.67845891714096  minutes\n"
          ]
        }
      ],
      "source": [
        "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "                                                 PPO_model_kwargs,\n",
        "                                                 DDPG_model_kwargs,\n",
        "                                                 timesteps_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "-0qd8acMtj1f",
        "outputId": "a48c565b-320a-4886-d650-53db00151f20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
              "0  126  2021-10-04  2022-01-03        A2C   0.309893   0.211166    0.174301\n",
              "1  189  2022-01-03  2022-04-04       DDPG  -0.214642  -0.113722   -0.095308\n",
              "2  252  2022-04-04  2022-07-06        A2C  -0.198168  -0.335974   -0.216626\n",
              "3  315  2022-07-06  2022-10-04       DDPG   -0.27471  -0.266678   -0.125253"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf88fe2c-fe7a-43d6-a220-7884e9d94ed8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126</td>\n",
              "      <td>2021-10-04</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.309893</td>\n",
              "      <td>0.211166</td>\n",
              "      <td>0.174301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>189</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>2022-04-04</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.214642</td>\n",
              "      <td>-0.113722</td>\n",
              "      <td>-0.095308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>252</td>\n",
              "      <td>2022-04-04</td>\n",
              "      <td>2022-07-06</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.198168</td>\n",
              "      <td>-0.335974</td>\n",
              "      <td>-0.216626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>315</td>\n",
              "      <td>2022-07-06</td>\n",
              "      <td>2022-10-04</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.27471</td>\n",
              "      <td>-0.266678</td>\n",
              "      <td>-0.125253</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf88fe2c-fe7a-43d6-a220-7884e9d94ed8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf88fe2c-fe7a-43d6-a220-7884e9d94ed8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf88fe2c-fe7a-43d6-a220-7884e9d94ed8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest OurÂ Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "X4JKB--8tj1g"
      },
      "outputs": [],
      "source": [
        "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9mKF7GGtj1g",
        "outputId": "0908f3c8-0eb6-4e28-9196-0f3ed4d5c498",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpe Ratio:  -0.25140082312654227\n"
          ]
        }
      ],
      "source": [
        "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
        "\n",
        "df_account_value=pd.DataFrame()\n",
        "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
        "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
        "\n",
        "    # append is deprecated\n",
        "    # df_account_value = df_account_value.append(temp,ignore_index=True)\n",
        "    df_account_value = pd.concat([df_account_value, pd.DataFrame(temp)], ignore_index=True)\n",
        "\n",
        "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
        "print('Sharpe Ratio: ',sharpe)\n",
        "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oyosyW7_tj1g",
        "outputId": "9a91aa2b-6a78-4978-8084-75f564195616"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   account_value        date  daily_return    datadate\n",
              "0   1.000000e+06  2022-01-03           NaN  2022-01-03\n",
              "1   1.000744e+06  2022-01-04      0.000744  2022-01-04\n",
              "2   9.978236e+05  2022-01-05     -0.002919  2022-01-05\n",
              "3   9.975824e+05  2022-01-06     -0.000242  2022-01-06\n",
              "4   1.000243e+06  2022-01-07      0.002667  2022-01-07"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70272bea-e7a5-4938-9bdc-a61ef969f0ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>datadate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-01-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000744e+06</td>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>0.000744</td>\n",
              "      <td>2022-01-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.978236e+05</td>\n",
              "      <td>2022-01-05</td>\n",
              "      <td>-0.002919</td>\n",
              "      <td>2022-01-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.975824e+05</td>\n",
              "      <td>2022-01-06</td>\n",
              "      <td>-0.000242</td>\n",
              "      <td>2022-01-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000243e+06</td>\n",
              "      <td>2022-01-07</td>\n",
              "      <td>0.002667</td>\n",
              "      <td>2022-01-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70272bea-e7a5-4938-9bdc-a61ef969f0ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70272bea-e7a5-4938-9bdc-a61ef969f0ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70272bea-e7a5-4938-9bdc-a61ef969f0ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "df_account_value.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLsRdw2Ctj1h"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "df_account_value.account_value.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2zX7ZxNyFQ"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzkr9yv-AdV_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiHhM1YkoCel"
      },
      "outputs": [],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "df_dji_ = get_baseline(\n",
        "        ticker=\"^DJI\", \n",
        "        start = df_account_value.loc[0,'date'],\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(df_dji_, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dji = pd.DataFrame()\n",
        "df_dji['date'] = df_account_value['date']\n",
        "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji.csv\")\n",
        "df_dji = df_dji.set_index(df_dji.columns[0])\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji+.csv\")\n",
        "\n",
        "df_account_value.to_csv('df_account_value.csv')\n"
      ],
      "metadata": {
        "id": "RhJ9whD75WTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Suru3h1jc"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HggausPRoCem"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# print(\"==============Compare to DJIA===========\")\n",
        "# %matplotlib inline\n",
        "# # S&P 500: ^GSPC\n",
        "# # Dow Jones Index: ^DJI\n",
        "# # NASDAQ 100: ^NDX\n",
        "# backtest_plot(df_account_value, \n",
        "#               baseline_ticker = '^DJI', \n",
        "#               baseline_start = df_account_value.loc[0,'date'],\n",
        "#               baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "df.to_csv(\"df.csv\")\n",
        "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble': df_account_value['account_value']})\n",
        "df_result_ensemble = df_result_ensemble.set_index('date')\n",
        "\n",
        "print(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n",
        "\n",
        "# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\n",
        "print(\"df_trade_date: \", df_trade_date)\n",
        "# df_result_ensemble['date'] = df_trade_date['datadate']\n",
        "# df_result_ensemble['account_value'] = df_account_value['account_value']\n",
        "df_result_ensemble.to_csv(\"df_result_ensemble.csv\")\n",
        "print(\"df_result_ensemble: \", df_result_ensemble)\n",
        "print(\"==============Compare to DJIA===========\")\n",
        "result = pd.DataFrame()\n",
        "# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n",
        "# result = pd.merge(result, df_dji, left_index=True, right_index=True)\n",
        "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\n",
        "print(\"result: \", result)\n",
        "result.to_csv(\"result.csv\")\n",
        "result.columns = ['ensemble', 'dji']\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "plt.figure();\n",
        "result.plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oBQx4bVQFi-a"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}