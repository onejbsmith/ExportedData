{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAutH+xdPzvvzk2bbENQpX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onejbsmith/ExportedData/blob/main/Save_and_Load_Your_PyTorch_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Load Your PyTorch Models\n",
        "\n",
        "By [Adrian Tam](https://machinelearningmastery.com/author/adriantam/ \"Posts by Adrian Tam\") on February 13, 2023 in [Deep Learning with PyTorch](https://machinelearningmastery.com/category/deep-learning-with-pytorch/ \"View all items in Deep Learning with PyTorch\")\n",
        "\n",
        "_Tweet_ _Tweet_ Share Share\n",
        "\n",
        "Last Updated on April 8, 2023\n",
        "\n",
        "A deep learning model is a mathematical abstraction of data, in which a lot of parameters are involved. Training these parameters can take hours, days, and even weeks but afterward, you can make use of the result to apply on new data. This is called inference in machine learning. It is important to know how we can preserve the trained model in disk and later, load it for use in inference. In this post, you will discover how to save your PyTorch models to files and load them up again to make predictions. After reading this chapter, you will know:\n",
        "\n",
        "- What are states and parameters in a PyTorch model\n",
        "- How to save model states\n",
        "- How to load model states\n",
        "\n",
        "**Kick-start your project** with my book [Deep Learning with PyTorch](https://machinelearningmastery.com/deep-learning-with-pytorch/). It provides **self-study tutorials** with **working code**.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This post is in three parts; they are\n",
        "\n",
        "- Build an Example Model\n",
        "- What’s Inside a PyTorch Model\n",
        "- Accessing `state_dict` of a Model\n",
        "\n",
        "## Build an Example Model\n",
        "\n",
        "Let’s start with a very simple model in PyTorch. It is a model based on the iris dataset. You will load the dataset using scikit-learn (which the targets are integer labels 0, 1, and 2) and train a neural network for this multiclass classification problem. In this model, you used log softmax as the output activation so you can combine with the negative log likelihood loss function. It is equivalent to no output activation combined with cross entropy loss function."
      ],
      "metadata": {
        "id": "6CbbmPzjUPYI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "kTfWhn4fSilV"
      },
      "outputs": [],
      "source": [
        "#@title Example Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data into NumPy arrays\n",
        "data = load_iris()\n",
        "X, y = data[\"data\"], data[\"target\"]\n",
        "\n",
        "# convert NumPy array into PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
        "\n",
        "# PyTorch model\n",
        "class Multiclass(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(4, 8)\n",
        "        self.act = nn.ReLU()\n",
        "        self.output = nn.Linear(8, 3)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.hidden(x))\n",
        "        x = self.logsoftmax(self.output(x))\n",
        "        return x\n",
        "\n",
        "model = Multiclass()\n",
        "    \n",
        "# loss metric and optimizer\n",
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# prepare model and training parameters\n",
        "n_epochs = 100\n",
        "batch_size = 5\n",
        "batch_start = torch.arange(0, len(X), batch_size)\n",
        "\n",
        "# training loop\n",
        "for epoch in range(n_epochs):\n",
        "    for start in batch_start:\n",
        "        # take a batch\n",
        "        X_batch = X_train[start:start+batch_size]\n",
        "        y_batch = y_train[start:start+batch_size]\n",
        "        # forward pass\n",
        "        y_pred = model(X_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # update weights\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #####With such a simple model and small dataset, it shouldn’t take a long time to finish training. Afterwards, we can confirm that this model works, by evaluating it with the test set:\n",
        "...\n",
        "y_pred = model(X_test)\n",
        "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
        "print(\"Accuracy: %.2f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yzik0VQS0ZE",
        "outputId": "eeddf5bb-4f5f-4011-e805-93a004c5e7bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What’s Inside a PyTorch Model\n",
        "\n",
        "PyTorch model is an object in Python. It holds some deep learning building blocks such as various kinds of layers and activation functions. It also knows how to connect them so it can produce you an output from your input tensors. The algorithm of a model is fixed at the time you created it, however, it has trainable parameters that is supposed to be modified during training loop so the model can be more accurate.\n",
        "\n",
        "You saw how to get the model parameters when you set up the optimizer for your training loop, namely,"
      ],
      "metadata": {
        "id": "CAVMol2gY40R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer"
      ],
      "metadata": {
        "id": "FcOuO5zEZJWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #####The function `model.parameters()` give you a generator that references each layers’ trainable parameters in turn in the form of PyTorch tensors. Therefore, it is possible for you to make a copy of them or overwrite them, for example:\n",
        "\n",
        "# Create a new model\n",
        "newmodel = Multiclass()\n",
        "\n",
        "# Ask PyTorch to ignore autograd on update and overwrite parameters\n",
        "# Copy old tensor from model.parameters() to new tensor of newmodel.parameters()\n",
        "with torch.no_grad():\n",
        "    for newtensor, oldtensor in zip(newmodel.parameters(), model.parameters()):\n",
        "        newtensor.copy_(oldtensor)\n",
        "\n",
        "# newmodel has been initialized by copying its \n",
        "# parameter tenso from model\n",
        "\n",
        "# test with new model using copied tensor\n",
        "y_pred = newmodel(X_test)\n",
        "\n",
        "# show accuracy\n",
        "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
        "print(\"Accuracy: %.2f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVQCQdL7Txjc",
        "outputId": "89be7fa5-1f2e-4748-d37d-fbd29986a8a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which the result should be exactly the same as before since you essentially made the two models identical by copying the parameters.\n",
        "\n",
        "However, this is not always the case. Some models has **non-trainable parameters**. One example is the batch normalization layer that is common in many convolution neural networks. What it does is to apply normalization on tensors that produced by its previous layer and pass on the normalized tensor to its next layer. It has two parameters: The mean and standard deviation, which are learned from your input data during training loop but not trainable by the optimizer. Therefore these are not part of `model.parameters()` but equally important.\n",
        "\n",
        "## Accessing `state_dict` of a Model\n",
        "\n",
        "To access all parameters of a model, trainable or not, you can get it from `state_dict()` function. From the model above, this is what you can get:"
      ],
      "metadata": {
        "id": "D2UsZdW6bkBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pp.pprint(model.state_dict())"
      ],
      "metadata": {
        "id": "7CLWhsSubw2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is called `state_dict` because all state variables of a model are here. It is an `OrderedDict` object from Python’s built-in `collections` module. All components from a PyTorch model has a name and so as the parameters therein. The `OrderedDict` object allows you to map the weights back to the parameters correctly by matching their names.\n",
        "\n",
        "This is how you should save and load the model: Fetch the model states into an `OrderedDict`, serialize and save it to disk. For inference, you create a model first (without training), and load the states. In Python, the native format for serialization is pickle:"
      ],
      "metadata": {
        "id": "QMll4XyhcOWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save model\n",
        "import pickle\n",
        "\n",
        "# Save model\n",
        "with open(\"iris-model.pickle\", \"wb\") as fp:\n",
        "    pickle.dump(model.state_dict(), fp)\n",
        "    \n",
        "# Create new model and load states\n",
        "newmodel = Multiclass()\n",
        "with open(\"iris-model.pickle\", \"rb\") as fp:\n",
        "    newmodel.load_state_dict(pickle.load(fp))\n",
        "\n",
        "# test with new model using copied tensor\n",
        "y_pred = newmodel(X_test)\n",
        "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
        "print(\"Accuracy: %.2f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpGVi0uecYoH",
        "outputId": "7b47a095-0a41-407c-9b50-45eb16baf0ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You know it works because the model you didn’t train produced the same result as the one you trained.\n",
        "\n",
        "Indeed, the recommended way is to use the PyTorch API to save and load the states, instead of using pickle manually:"
      ],
      "metadata": {
        "id": "20SULfb3czW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save model\n",
        "torch.save(model.state_dict(), \"iris-model.pth\")\n",
        "\n",
        "# Create new model and load states\n",
        "newmodel = Multiclass()\n",
        "newmodel.load_state_dict(torch.load(\"iris-model.pth\"))\n",
        "\n",
        "# test with new model using copied tensor\n",
        "y_pred = newmodel(X_test)\n",
        "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
        "print(\"Accuracy: %.2f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFaJUMiFc6Ko",
        "outputId": "6000d852-ee7c-4581-846d-5ff61e9b3db9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `*.pth` file is indeed a zip file of some pickle files created by PyTorch. It is recommended because PyTorch can store additional information in it. Note that you stored only the states but not the model. You still need to create the model using Python code and load the states into it. If you wish to store the model as well, you can pass in the entire model instead of the states:"
      ],
      "metadata": {
        "id": "RRgL2ZQcdUt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Save model\n",
        "torch.save(model, \"iris-model-full.pth\")\n",
        " \n",
        "# Load model\n",
        "newmodel = torch.load(\"iris-model-full.pth\")\n",
        " \n",
        "# test with new model using copied tensor\n",
        "y_pred = newmodel(X_test)\n",
        "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
        "print(\"Accuracy: %.2f\" % acc)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "szB0VIetdW69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But remember, due to the nature of Python language, doing so does not relieve you from keeping the code of the model. The `newmodel` object above is an instance of `Multiclass` class that you defined before. When you load the model from disk, Python need to know in detail how this class is defined. If you run a script with just the line `torch.load()`, you will see the following error message:\n",
        "\n",
        "Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"/.../torch/serialization.py\", line 789, in load return \\_load(opened\\_zipfile, map\\_location, pickle\\_module, \\*\\*pickle\\_load\\_args) File \"/.../torch/serialization.py\", line 1131, in \\_load result = unpickler.load() File \"/.../torch/serialization.py\", line 1124, in find\\_class return super().find\\_class(mod\\_name, name) AttributeError: Can't get attribute 'Multiclass' on <module '\\_\\_main\\_\\_' (built-in)>\n",
        "\n",
        "<table class=\"crayon-table\" style=\"\"><tbody><tr class=\"urvanov-syntax-highlighter-row\"><td class=\"crayon-nums \" data-settings=\"show\"><div class=\"urvanov-syntax-highlighter-nums-content\" style=\"font-size: 12px !important; line-height: 15px !important;\"><div class=\"crayon-num\" data-line=\"urvanov-syntax-highlighter-643a8358291ae326442672-1\">1</div><div class=\"crayon-num crayon-striped-num\" data-line=\"urvanov-syntax-highlighter-643a8358291ae326442672-2\">2</div><div class=\"crayon-num\" data-line=\"urvanov-syntax-highlighter-643a8358291ae326442672-3\">3</div><div class=\"crayon-num crayon-striped-num\" data-line=\"urvanov-syntax-highlighter-643a8358291ae326442672-4\">4</div><div class=\"crayon-num\" data-line=\"urvanov-syntax-highlighter-643a8358291ae326442672-5\">5</div><div class=\"crayon-num crayon-striped-num\" data-line=\"urvanov-syntax-highlighter-643a8358291ae326442672-6\">6</div><div class=\"crayon-num\" data-line=\"urvanov-syntax-highlighter-643a8358291ae326442672-7\">7</div><div class=\"crayon-num crayon-striped-num\" data-line=\"urvanov-syntax-highlighter-643a8358291ae326442672-8\">8</div><div class=\"crayon-num\" data-line=\"urvanov-syntax-highlighter-643a8358291ae326442672-9\">9</div></div></td><td class=\"urvanov-syntax-highlighter-code\"><div class=\"crayon-pre\" style=\"font-size: 12px !important; line-height: 15px !important; -moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4;\"><div class=\"crayon-line\" id=\"urvanov-syntax-highlighter-643a8358291ae326442672-1\"><span class=\"crayon-e\">Traceback</span><span class=\"crayon-h\"> </span><span class=\"crayon-sy\">(</span><span class=\"crayon-e\">most </span><span class=\"crayon-e\">recent </span><span class=\"crayon-e\">call </span><span class=\"crayon-v\">last</span><span class=\"crayon-sy\">)</span><span class=\"crayon-o\">:</span></div><div class=\"crayon-line crayon-striped-line\" id=\"urvanov-syntax-highlighter-643a8358291ae326442672-2\"><span class=\"crayon-i\">File</span><span class=\"crayon-h\"> </span><span class=\"crayon-s\">\"&lt;stdin&gt;\"</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-i\">line</span><span class=\"crayon-h\"> </span><span class=\"crayon-cn\">1</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-st\">in</span><span class=\"crayon-h\"> </span><span class=\"crayon-o\">&lt;</span><span class=\"crayon-v\">module</span><span class=\"crayon-o\">&gt;</span></div><div class=\"crayon-line\" id=\"urvanov-syntax-highlighter-643a8358291ae326442672-3\"><span class=\"crayon-i\">File</span><span class=\"crayon-h\"> </span><span class=\"crayon-s\">\"/.../torch/serialization.py\"</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-i\">line</span><span class=\"crayon-h\"> </span><span class=\"crayon-cn\">789</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-st\">in</span><span class=\"crayon-h\"> </span><span class=\"crayon-e\">load</span></div><div class=\"crayon-line crayon-striped-line\" id=\"urvanov-syntax-highlighter-643a8358291ae326442672-4\"><span class=\"crayon-st\">return</span><span class=\"crayon-h\"> </span><span class=\"crayon-e\">_load</span><span class=\"crayon-sy\">(</span><span class=\"crayon-v\">opened_zipfile</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-v\">map_location</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-v\">pickle_module</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-o\">*</span><span class=\"crayon-o\">*</span><span class=\"crayon-v\">pickle_load_args</span><span class=\"crayon-sy\">)</span></div><div class=\"crayon-line\" id=\"urvanov-syntax-highlighter-643a8358291ae326442672-5\"><span class=\"crayon-i\">File</span><span class=\"crayon-h\"> </span><span class=\"crayon-s\">\"/.../torch/serialization.py\"</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-i\">line</span><span class=\"crayon-h\"> </span><span class=\"crayon-cn\">1131</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-st\">in</span><span class=\"crayon-h\"> </span><span class=\"crayon-e\">_load</span></div><div class=\"crayon-line crayon-striped-line\" id=\"urvanov-syntax-highlighter-643a8358291ae326442672-6\"><span class=\"crayon-v\">result</span><span class=\"crayon-h\"> </span><span class=\"crayon-o\">=</span><span class=\"crayon-h\"> </span><span class=\"crayon-v\">unpickler</span><span class=\"crayon-sy\">.</span><span class=\"crayon-e\">load</span><span class=\"crayon-sy\">(</span><span class=\"crayon-sy\">)</span></div><div class=\"crayon-line\" id=\"urvanov-syntax-highlighter-643a8358291ae326442672-7\"><span class=\"crayon-i\">File</span><span class=\"crayon-h\"> </span><span class=\"crayon-s\">\"/.../torch/serialization.py\"</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-i\">line</span><span class=\"crayon-h\"> </span><span class=\"crayon-cn\">1124</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-st\">in</span><span class=\"crayon-h\"> </span><span class=\"crayon-e\">find_class</span></div><div class=\"crayon-line crayon-striped-line\" id=\"urvanov-syntax-highlighter-643a8358291ae326442672-8\"><span class=\"crayon-st\">return</span><span class=\"crayon-h\"> </span><span class=\"crayon-r\">super</span><span class=\"crayon-sy\">(</span><span class=\"crayon-sy\">)</span><span class=\"crayon-sy\">.</span><span class=\"crayon-e\">find_class</span><span class=\"crayon-sy\">(</span><span class=\"crayon-v\">mod_name</span><span class=\"crayon-sy\">,</span><span class=\"crayon-h\"> </span><span class=\"crayon-v\">name</span><span class=\"crayon-sy\">)</span></div><div class=\"crayon-line\" id=\"urvanov-syntax-highlighter-643a8358291ae326442672-9\"><span class=\"crayon-v\">AttributeError</span><span class=\"crayon-o\">:</span><span class=\"crayon-h\"> </span><span class=\"crayon-i\">Can</span><span class=\"crayon-s\">'t get attribute '</span><span class=\"crayon-i\">Multiclass</span><span class=\"crayon-s\">' on &lt;module '</span><span class=\"crayon-v\">__main_</span><span class=\"crayon-sy\">_</span>'<span class=\"crayon-h\"> </span><span class=\"crayon-sy\">(</span><span class=\"crayon-v\">built</span><span class=\"crayon-o\">-</span><span class=\"crayon-st\">in</span><span class=\"crayon-sy\">)</span><span class=\"crayon-o\">&gt;</span></div></div></td></tr></tbody></table>\n",
        "\n",
        "That’s why it is recommended to save only the state dict rather than the entire model.\n",
        "\n",
        "Putting everything together, the following is the complete code to demonstrate how to create a model, train it, and save to disk:"
      ],
      "metadata": {
        "id": "3zrR3mundvQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title How to create a model, train it, and save to disk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data into NumPy arrays\n",
        "data = load_iris()\n",
        "X, y = data[\"data\"], data[\"target\"]\n",
        "\n",
        "# convert NumPy array into PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
        "\n",
        "# PyTorch model\n",
        "class Multiclass(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(4, 8)\n",
        "        self.act = nn.ReLU()\n",
        "        self.output = nn.Linear(8, 3)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.hidden(x))\n",
        "        x = self.logsoftmax(self.output(x))\n",
        "        return x\n",
        "\n",
        "model = Multiclass()\n",
        "    \n",
        "# loss metric and optimizer\n",
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# prepare model and training parameters\n",
        "n_epochs = 100\n",
        "batch_size = 5\n",
        "batch_start = torch.arange(0, len(X), batch_size)\n",
        "\n",
        "# training loop\n",
        "for epoch in range(n_epochs):\n",
        "    for start in batch_start:\n",
        "        # take a batch\n",
        "        X_batch = X_train[start:start+batch_size]\n",
        "        y_batch = y_train[start:start+batch_size]\n",
        "        # forward pass\n",
        "        y_pred = model(X_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"iris-model.pth\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3dHLK_LkdyDG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title And the following is how to load the model from disk and run it for inference:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data into NumPy arrays\n",
        "data = load_iris()\n",
        "X, y = data[\"data\"], data[\"target\"]\n",
        "\n",
        "# convert NumPy array into PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# PyTorch model\n",
        "class Multiclass(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(4, 8)\n",
        "        self.act = nn.ReLU()\n",
        "        self.output = nn.Linear(8, 3)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.hidden(x))\n",
        "        x = self.logsoftmax(self.output(x))\n",
        "        return x\n",
        "\n",
        "# Create new model and load states\n",
        "model = Multiclass()\n",
        "with open(\"iris-model.pickle\", \"rb\") as fp:\n",
        "    model.load_state_dict(pickle.load(fp))\n",
        "\n",
        "# Run model for inference\n",
        "y_pred = model(X_test)\n",
        "acc = (torch.argmax(y_pred, 1) == y_test).float().mean()\n",
        "print(\"Accuracy: %.2f\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVPwx_GnewoH",
        "outputId": "a332656c-5807-49af-8024-19f23fe324a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further Readings\n",
        "\n",
        "This section provides more resources on the topic if you are looking to go deeper.\n",
        "\n",
        "- [Saving and loading models](https://pytorch.org/tutorials/beginner/saving_loading_models.html) from PyTorch tutorial\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this post, you learned how to keep a copy of your trained PyTorch model in disk and how to reuse it. In particular, you learned\n",
        "\n",
        "- What are parameters and states in a PyTorch model\n",
        "- How to save all necessary states from a model to disk\n",
        "- How to rebuild a working model from the saved states\n",
        "\n",
        "## Get Started on Deep Learning with PyTorch!\n",
        "\n",
        "[![Deep Learning with PyTorch](https://machinelearningmastery.com/wp-content/uploads/2023/03/DLWPT-220.jpg)](https://machinelearningmastery.com/deep-learning-with-pytorch/)\n",
        "\n",
        "#### Learn how to build deep learning models\n",
        "\n",
        "...using the newly released PyTorch 2.0 library\n",
        "\n",
        "Discover how in my new Ebook:  \n",
        "[Deep Learning with PyTorch](https://machinelearningmastery.com/deep-learning-with-pytorch/)\n",
        "\n",
        "It provides **self-study tutorials** with **hundreds of working code** to turn you from a novice to expert. It equips you with  \n",
        "_tensor operation_, _training_, _evaluation_, _hyperparameter optimization_, and much more...\n",
        "\n",
        "#### Kick-start your deep learning journey with hands-on exercises\n",
        "\n",
        "  \n",
        "\n",
        "[See What's Inside](https://machinelearningmastery.com/deep-learning-with-pytorch/)"
      ],
      "metadata": {
        "id": "2wLxfXh-fQlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9joU0lmfT9Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}